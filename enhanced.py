import time
import json
import gspread
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from datetime import datetime, timedelta, date
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import APIError

# --- Streamlitãƒšãƒ¼ã‚¸ã®åŸºæœ¬è¨­å®š ---
st.set_page_config(layout="wide", page_title="HubSpotãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# --- è¨­å®šå€¤ ---
CONFIG = {
    "scope": ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"],
    "deals_sheet": "Deals",
    "stages_sheet": "OtherParams",
    "users_sheet": "Users",
    "max_retries": 3,
    "retry_delay": 5
}

# --- Authentication ---
try:
    credentials_dict = json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, CONFIG["scope"])
    gc = gspread.authorize(creds)
except KeyError:
    st.error("Googleã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`st.secrets`ã«`GOOGLE_SERVICE_ACCOUNT`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

try:
    SPREADSHEET_KEY = st.secrets["SPREADSHEET_KEY"]
except KeyError:
    st.error("Google Sheetsã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`st.secrets`ã«`SPREADSHEET_KEY`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- Functions (å®šç¾©ã‚’ã¾ã¨ã‚ã¦é…ç½®) ---

@st.cache_data(ttl=300, show_spinner="Google Sheets ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
def load_data_with_retry():
    """
    Fetches data from Google Sheets and retries if an API rate limit is reached.
    """
    attempt = 0
    while attempt < CONFIG["max_retries"]:
        try:
            deals_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(CONFIG["deals_sheet"])
            stages_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(CONFIG["stages_sheet"])
            users_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(CONFIG["users_sheet"])

            deals_data = pd.DataFrame(deals_ws.get_all_records())
            stages_data = pd.DataFrame(stages_ws.get("A2:B23"), columns=["Stage No", "Stage Name"])
            users_data = pd.DataFrame(users_ws.get_all_records())
            funnel_mapping_raw = stages_ws.get("E1:H14")
            funnel_mapping = pd.DataFrame(funnel_mapping_raw[1:], columns=funnel_mapping_raw[0])
            return deals_data, stages_data, users_data, funnel_mapping

        except APIError as e:
            if "429" in str(e):
                st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{CONFIG['retry_delay']}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...ï¼ˆ{attempt + 1}/{CONFIG['max_retries']}ï¼‰")
                time.sleep(CONFIG["retry_delay"])
                attempt += 1
            else:
                st.error(f"Google Sheets API ã‚¨ãƒ©ãƒ¼: {e}")
                break

    st.error("Google Sheetsã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¾Œã»ã©å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
    return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

def preprocess_data(deals, stages, users, funnel_mapping):
    """
    ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’1ã¤ã®é–¢æ•°ã«ã¾ã¨ã‚ã‚‹
    """

    users_df = users.copy()
    users_df["Full Name"] = users_df["Last Name"].fillna("") + " " + users_df["First Name"].fillna("")
    users_df = users_df.rename(columns={"ID": "User ID"})
    
    deals_df = deals.copy()
    
    # ğŸ’¡ ä¿®æ­£ç‚¹: åˆ—åã‚’æœ€åˆã«ãƒªãƒãƒ¼ãƒ ã—ã¾ã™ã€‚
    deals_df = deals_df.rename(columns={"Deal owner": "User ID", "Deal Stage (name)": "Stagename", "Deal Stage": "Stage No"})
    
    deals_df["User ID"] = pd.to_numeric(deals_df["User ID"], errors="coerce")
    
    # ğŸ’¡ ä¿®æ­£ç‚¹: ãƒªãƒãƒ¼ãƒ å¾Œã€æ–°ã—ã„åˆ—å "Stage No" ã‚’ä½¿ã£ã¦æ•°å€¤å¤‰æ›ã—ã¾ã™ã€‚
    deals_df["Stage No"] = pd.to_numeric(deals_df["Stage No"], errors="coerce")
    deals_df['Pipeline (name)'] = deals_df['Pipeline (name)'].astype(str).str.strip()
    deals_df['Stagename'] = deals_df['Stagename'].astype(str).str.strip()

    stages_df = stages.copy()
    stages_df["Stage No"] = pd.to_numeric(stages_df["Stage No"], errors="coerce")

    deals_df['å—æ³¨é‡‘é¡'] = deals_df['å—æ³¨é‡‘é¡'].astype(str).str.replace(r'[^\d]', '', regex=True)
    deals_df["å—æ³¨é‡‘é¡"] = pd.to_numeric(deals_df["å—æ³¨é‡‘é¡"], errors="coerce")

    merged_df = deals_df.merge(users_df[["User ID", "Full Name"]], on="User ID", how="left")
    
    # ğŸ’¡ ä¿®æ­£ç‚¹: ãƒªãƒãƒ¼ãƒ ã—ãŸ`Stage No`åˆ—ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨
    merged_df = merged_df.merge(stages_df, on="Stage No", how="left")

    anken_type_categories = ["New", "Upsell", "Renewal", "Other"]
    def agg_anken_type(val) -> str:
        if pd.isna(val): return "Other"
        s = str(val).strip().lower()
        if s in ("newbusiness", "new business", "new"): return "New"
        if s in ("existingbusiness", "existing business", "upsell", "cross-sell", "cross sell", "expansion", "csã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "cså°å…¥ã‚µãƒ¼ãƒ“ã‚¹"): return "Upsell"
        if s in ("renewal", "renew"): return "Renewal"
        return "Other"
    merged_df["Anken Type"] = (
        merged_df["Deal Type"]
        .apply(agg_anken_type)
        .astype(pd.CategoricalDtype(categories=anken_type_categories, ordered=True))
    )
    
    date_columns = [
        'åˆå›å•†è«‡å®Ÿæ–½æ—¥', 'å—æ³¨æ—¥', 'å—æ³¨ç›®æ¨™æ—¥', 'æœ‰å„Ÿãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç™ºè¡Œ', 'æ¦‚ç®—è¦‹ç©æå‡ºæ—¥', 'å ±å‘Š/ææ¡ˆæ—¥',
        'æœ€çµ‚è¦‹ç©æå‡ºæ—¥', 'Create Date', 'æ´»å‹•ææ¡ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³', 'å®Ÿæ–½äºˆå®šæ—¥', 'Close Date',
        'ç¾åœ°ãƒ‡ãƒ¢å®Ÿæ–½æ—¥', 'å–¶æ¥­å¼•ç¶™ãæ—¥', 'æ’®åƒ/è§£æå®Œäº†æ—¥', 'æ’®å½±æ—¥', 'å¤±æ³¨æ—¥',
        'Snapshot_date', 'æ²»å…·æ‰‹é…æ—¥', 'æ¤œè¨¼_é–‹å§‹æ—¥'
    ]
    for col in date_columns:
        if col in merged_df.columns:
            merged_df[col] = pd.to_datetime(merged_df[col], errors='coerce').dt.tz_localize(None)
            
    # â–¼ ä¿®æ­£å¾Œã®ãƒ­ã‚¸ãƒƒã‚¯ â–¼
    def determine_stage_and_funnel_with_debug(row, mapping_df):
        deals_pipeline = str(row.get('Pipeline (name)', ''))
        deals_stage = str(row.get('Stagename', ''))
        
        # 1. Pipelineã¨å–å¼•ã‚¹ãƒ†ãƒ¼ã‚¸ã®ä¸¡æ–¹ã§å®Œå…¨ä¸€è‡´ã‚’æ¢ã™
        exact_match = mapping_df[
            (mapping_df['Pipeline'].astype(str).str.strip() == deals_pipeline) &
            (mapping_df['å–å¼•ã‚¹ãƒ†ãƒ¼ã‚¸'].astype(str).str.strip() == deals_stage)
        ]
        if not exact_match.empty:
            debug_message = "Mapping Success!: " + exact_match.iloc[0]['ãƒ•ã‚¡ãƒãƒ«åç§°']
            return exact_match.iloc[0]['Stage ID'], exact_match.iloc[0]['ãƒ•ã‚¡ãƒãƒ«åç§°'], debug_message

        # 2. PipelineãŒä¸€è‡´ã—ã€å–å¼•ã‚¹ãƒ†ãƒ¼ã‚¸ãŒç©ºã®è¡Œã‚’æ¢ã™ï¼ˆæ¡ˆä»¶åŒ–å‰ã€æˆç´„ï¼‰
        empty_stage_mapping = mapping_df[
            (mapping_df['Pipeline'].astype(str).str.strip() == deals_pipeline) &
            (mapping_df['å–å¼•ã‚¹ãƒ†ãƒ¼ã‚¸'].fillna('').astype(str).str.strip() == '')
        ]
        if not empty_stage_mapping.empty:
            debug_message = "Mapping Success (empty stage)!: " + empty_stage_mapping.iloc[0]['ãƒ•ã‚¡ãƒãƒ«åç§°']
            return empty_stage_mapping.iloc[0]['Stage ID'], empty_stage_mapping.iloc[0]['ãƒ•ã‚¡ãƒãƒ«åç§°'], debug_message
        
        # 3. ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰ã®ãƒ­ã‚¸ãƒƒã‚¯
        fuzzy_match_rows = mapping_df[
            (mapping_df['Pipeline'].astype(str).str.strip() == deals_pipeline) &
            (mapping_df['å–å¼•ã‚¹ãƒ†ãƒ¼ã‚¸'].astype(str).str.strip().str.len() > 0)
        ]

        for index, mapping_row in fuzzy_match_rows.iterrows():
            mapping_stage = mapping_row['å–å¼•ã‚¹ãƒ†ãƒ¼ã‚¸'].strip()
            if (deals_stage in mapping_stage) or (mapping_stage in deals_stage):
                debug_message = "Mapping Success (fuzzy match)!: " + mapping_row['ãƒ•ã‚¡ãƒãƒ«åç§°']
                return mapping_row['Stage ID'], mapping_row['ãƒ•ã‚¡ãƒãƒ«åç§°'], debug_message

        # 4. ã©ã®æ¡ä»¶ã«ã‚‚ä¸€è‡´ã—ãªã‹ã£ãŸå ´åˆ
        debug_message = f"Mapping failed. Pipeline (name): '{deals_pipeline}', Deal Stage (name): '{deals_stage}'"
        return None, None, debug_message
    
    # Apply the mapping function to the merged dataframe
    # This unpacks the three values returned by determine_stage_and_funnel_with_debug
    # into new columns on the merged_df.
    merged_df[['Funnel_Stage_ID', 'Funnel_Name', 'Funnel_Debug_Info']] = merged_df.apply(
        lambda row: determine_stage_and_funnel_with_debug(row, funnel_mapping),
        axis=1,
        result_type='expand'
    )
    
    # Return the processed dataframes to the main application
    return merged_df, stages_df, funnel_mapping
def get_fiscal_dates(today, fiscal_start_month=1):
    """
    æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ã¨ä¼šè¨ˆå¹´åº¦ã®é–‹å§‹æœˆã«åŸºã¥ã„ã¦ã€ä¼šè¨ˆå¹´åº¦ã€åŠæœŸã€å››åŠæœŸã®é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
    """
    current_year = today.year
    current_month = today.month

    # ä¼šè¨ˆå¹´åº¦ã®é–‹å§‹ã¨çµ‚äº†ã‚’è¨ˆç®—
    if current_month >= fiscal_start_month:
        fiscal_year_start = datetime.datetime(current_year, fiscal_start_month, 1).date()
    else:
        fiscal_year_start = datetime.datetime(current_year - 1, fiscal_start_month, 1).date()

    fiscal_year_end = datetime.datetime(fiscal_year_start.year + 1, fiscal_start_month, 1).date() - datetime.timedelta(days=1)

    # åŠæœŸã®é–‹å§‹ã¨çµ‚äº†ã‚’è¨ˆç®—
    if current_month >= fiscal_start_month and current_month < fiscal_start_month + 6:
        half_year_start = fiscal_year_start
    else:
        half_year_start = datetime.datetime(fiscal_year_start.year, fiscal_start_month + 6, 1).date()
    
    half_year_end = datetime.datetime(half_year_start.year, half_year_start.month + 6, 1).date() - datetime.timedelta(days=1)

    # ç¾åœ¨ã®æœˆã®å››åŠæœŸã®é–‹å§‹æœˆã‚’è¨ˆç®—
    # å››åŠæœŸã¯3ãƒ¶æœˆã”ã¨
    
    # ä¼šè¨ˆå¹´åº¦ã®é–‹å§‹æœˆã‚’åŸºæº–ã¨ã—ã¦ã€ç¾åœ¨ã®æœˆãŒã©ã®å››åŠæœŸã«å±ã™ã‚‹ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
    # ä¾‹ï¼š4æœˆå§‹ã¾ã‚Šã®å ´åˆã€Q1ã¯4-6æœˆã€Q2ã¯7-9æœˆã€Q3ã¯10-12æœˆã€Q4ã¯1-3æœˆ
    
    # ç°¡æ½”ã«ã™ã‚‹ãŸã‚ã«ã€ç¾åœ¨ã®æœˆã¨ä¼šè¨ˆå¹´åº¦é–‹å§‹æœˆã®ç›¸å¯¾çš„ãªå·®ã‚’è€ƒæ…®ã—ã¾ã™ã€‚
    month_diff = (current_month - fiscal_start_month) % 12
    quarter_index = month_diff // 3
    
    # åŸºæº–æœˆã‚’å››åŠæœŸã®é–‹å§‹æœˆã«åˆã‚ã›ã‚‹
    quarter_start_month = fiscal_start_month + (quarter_index * 3)

    # 12ã‚’è¶…ãˆã‚‹å ´åˆã¯èª¿æ•´
    if quarter_start_month > 12:
        quarter_start_month -= 12
        
    # å››åŠæœŸã®é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã‚’è¨ˆç®—
    quarter_start_year = fiscal_year_start.year
    if quarter_start_month < fiscal_start_month:
        quarter_start_year += 1
        
    quarter_start = datetime.datetime(quarter_start_year, quarter_start_month, 1).date()

    end_month = quarter_start.month + 3
    end_year = quarter_start.year
    if end_month > 12:
        end_month -= 12
        end_year += 1
    quarter_end = datetime.datetime(end_year, end_month, 1).date() - datetime.timedelta(days=1)
    
    return (
        fiscal_year_start, fiscal_year_end,
        half_year_start, half_year_end,
        quarter_start, quarter_end
    )

def display_kpis(df, start_date, end_date):
    st.subheader("ä¸»è¦KPI")
    st.markdown(f"**æ—¥ä»˜ç¯„å›²:** {start_date.strftime('%Y/%m/%d')} ~ {end_date.strftime('%Y/%m/%d')}")
    won_deals_df = df[df['å—æ³¨/å¤±æ³¨'] == 'å—æ³¨'].copy()
    
    total_won_value = won_deals_df["å—æ³¨é‡‘é¡"].sum() if not won_deals_df.empty else 0
    num_won_deals = len(won_deals_df)

    avg_deal_duration = 0
    if not won_deals_df.empty:
        won_deals_df = won_deals_df.dropna(subset=['åˆå›å•†è«‡å®Ÿæ–½æ—¥', 'å—æ³¨æ—¥'])
        if not won_deals_df.empty:
            won_deals_df['deal_duration'] = (won_deals_df['å—æ³¨æ—¥'] - won_deals_df['åˆå›å•†è«‡å®Ÿæ–½æ—¥']).dt.days
            avg_deal_duration = won_deals_df['deal_duration'].mean()

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(label="åˆè¨ˆå—æ³¨é‡‘é¡", value=f"{total_won_value:,.0f} ä¸‡å††")
    with col2:
        st.metric(label="å—æ³¨æ¡ˆä»¶æ•°", value=f"{num_won_deals}")
    with col3:
        st.metric(label="å¹³å‡æ¡ˆä»¶æœŸé–“", value=f"{avg_deal_duration:,.0f} æ—¥")


def create_funnel_chart(df, funnel_mapping_df):
    st.subheader("æ¡ˆä»¶ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ãƒ•ã‚¡ãƒãƒ«ãƒãƒ£ãƒ¼ãƒˆ")
    if df.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    fm = funnel_mapping_df.drop_duplicates('ãƒ•ã‚¡ãƒãƒ«åç§°').copy()
    fm['Stage ID'] = pd.to_numeric(fm['Stage ID'], errors='coerce')
    stage_order = fm.sort_values('Stage ID')['ãƒ•ã‚¡ãƒãƒ«åç§°'].tolist()
    
    funnel_data = df["Funnel_Name"].dropna().value_counts().reset_index()
    funnel_data.columns = ["Funnel_Name", "Count"]

    stage_order = funnel_mapping_df.drop_duplicates('ãƒ•ã‚¡ãƒãƒ«åç§°').sort_values('Stage ID')['ãƒ•ã‚¡ãƒãƒ«åç§°'].tolist()
    funnel_data['Funnel_Name'] = pd.Categorical(funnel_data['Funnel_Name'], categories=stage_order, ordered=True)
    funnel_data = funnel_data.sort_values("Funnel_Name", ascending=True)
    
    fig = go.Figure(go.Funnel(
        y = funnel_data["Funnel_Name"],
        x = funnel_data["Count"],
        textinfo = "value+percent initial",
        marker = {"color": ["deepskyblue", "lightseagreen", "cadetblue", "teal", "dodgerblue", "steelblue", "skyblue", "powderblue", "lightblue", "lightsteelblue"]}
    ))
    fig.update_layout(height=500, width=800, margin=dict(t=0, b=0, l=0, r=0))
    st.plotly_chart(fig, use_container_width=True)


def create_monthly_bar_chart(df):
    st.subheader("æœˆåˆ¥å—æ³¨é‡‘é¡")
    won_deals_df = df[df['å—æ³¨/å¤±æ³¨'] == 'å—æ³¨'].copy()

    if won_deals_df.empty:
        st.info("å—æ³¨æ¡ˆä»¶ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    won_deals_df['å—æ³¨æœˆ'] = won_deals_df['å—æ³¨æ—¥'].dt.to_period('M').astype(str)
    monthly_won = won_deals_df.groupby('å—æ³¨æœˆ')['å—æ³¨é‡‘é¡'].sum().reset_index()

    fig = px.bar(
        monthly_won,
        x="å—æ³¨æœˆ",
        y="å—æ³¨é‡‘é¡",
        title="æœˆåˆ¥å—æ³¨é‡‘é¡ã®æ¨ç§»",
        labels={"å—æ³¨é‡‘é¡": "å—æ³¨é‡‘é¡ (ä¸‡å††)"},
        color_discrete_sequence=px.colors.qualitative.Plotly
    )
    fig.update_layout(xaxis_title="å¹´æœˆ", yaxis_title="å—æ³¨é‡‘é¡ (ä¸‡å††)", xaxis={'categoryorder':'category ascending'})
    st.plotly_chart(fig, use_container_width=True)


def create_pipeline_chart(df, start_date, end_date):
    st.subheader("æ¡ˆä»¶ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ")
    df_plot = df.copy()
    
    # æ¬ æå€¤å‡¦ç†
    df_plot = df_plot.dropna(subset=['å—æ³¨æ—¥'])
    
    df_plot['Create Date'] = pd.to_datetime(df_plot['Create Date']).dt.date
    
    # æ¡ˆä»¶é–‹å§‹æ—¥ã®ä»£æ›¿å‡¦ç†
    df_plot['is_start_date_fallback'] = df_plot['åˆå›å•†è«‡å®Ÿæ–½æ—¥'].isna()
    df_plot['åˆå›å•†è«‡å®Ÿæ–½æ—¥'] = df_plot['åˆå›å•†è«‡å®Ÿæ–½æ—¥'].fillna(df_plot['Create Date'])
    df_plot['æ¡ˆä»¶å'] = df_plot['Deal Name'] + '<br>' + '(' + df_plot['ãƒªãƒ¼ãƒ‰çµŒè·¯'].fillna('ä¸æ˜') + ')'
    df_plot['Start'] = df_plot['åˆå›å•†è«‡å®Ÿæ–½æ—¥']
    df_plot['Finish'] = df_plot['å—æ³¨æ—¥']
    df_plot = df_plot.dropna(subset=['Start', 'Finish'])

    if df_plot.empty:
        st.info("ãƒ—ãƒ­ãƒƒãƒˆå¯èƒ½ãªæ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    df_plot = df_plot.sort_values('Start', ascending=False)
    
    fig = go.Figure()

    for _, row in df_plot.iterrows():
        fig.add_trace(go.Scatter(
            x=[row['Start'], row['Finish']],
            y=[row['æ¡ˆä»¶å'], row['æ¡ˆä»¶å']],
            mode='lines',
            line=dict(color='black', width=3),
            showlegend=False,
            hoverinfo='none'
        ))

        marker_color_start = 'gray' if row['is_start_date_fallback'] else 'blue'
        start_date_label = "æ¡ˆä»¶ä½œæˆæ—¥" if row['is_start_date_fallback'] else "åˆå›å•†è«‡å®Ÿæ–½æ—¥"
        
        fig.add_trace(go.Scatter(
            x=[row['Start']],
            y=[row['æ¡ˆä»¶å']],
            mode='markers',
            marker=dict(color=marker_color_start, size=10, symbol='circle'),
            name=f"{row['Deal Name']} (é–‹å§‹)",
            showlegend=False,
            hoverinfo='text',
            hovertext=f"æ¡ˆä»¶å: {row['Deal Name']}<br>å–¶æ¥­æ‹…å½“:{row['Full Name']}<br>æ—¥ä»˜: {row['Start'].strftime('%Y-%m-%d')}<br>ç¨®åˆ¥: {start_date_label}"
        ))

        text_label = f"{row['å—æ³¨é‡‘é¡']:,.0f}ä¸‡å††" if row['å—æ³¨/å¤±æ³¨'] == 'å—æ³¨' and pd.notna(row['å—æ³¨é‡‘é¡']) else 'å¤±æ³¨'
        marker_color_end = 'red' if row['å—æ³¨/å¤±æ³¨'] == 'å—æ³¨' else 'gray'

        fig.add_trace(go.Scatter(
            x=[row['Finish']],
            y=[row['æ¡ˆä»¶å']],
            mode='markers+text',
            marker=dict(color=marker_color_end, size=10, symbol='circle'),
            text=[text_label],
            textposition="middle right",
            name=f"{row['Deal Name']} (çµ‚äº†)",
            showlegend=False,
            hoverinfo='text',
            hovertext=f"æ¡ˆä»¶å: {row['Deal Name']}<br>é‡‘é¡: {text_label}"
        ))
        
        for mid_col, mid_label, mid_color, mid_symbol in [
            ('å ±å‘Š/ææ¡ˆæ—¥', 'å ±å‘Š/ææ¡ˆæ—¥', 'green', 'diamond'),
            ('æ¦‚ç®—è¦‹ç©æå‡ºæ—¥', 'æ¦‚ç®—è¦‹ç©æå‡ºæ—¥', 'purple', 'diamond')
        ]:
            if mid_col in df_plot.columns and pd.notna(row[mid_col]):
                fig.add_trace(go.Scatter(
                    x=[row[mid_col]],
                    y=[row['æ¡ˆä»¶å']],
                    mode='markers',
                    marker=dict(color=mid_color, size=7, symbol=mid_symbol),
                    name=f"{row['Deal Name']} ({mid_label})",
                    showlegend=False,
                    hoverinfo='text',
                    hovertext=f"{mid_label}: {row[mid_col].strftime('%Y-%m-%d')}"
                ))

    fig.update_layout(
        title="æ¡ˆä»¶ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆé–‹å§‹æ—¥ã€œçµ‚äº†æ—¥ï¼‰",
        xaxis_title="å¹´æœˆ",
        yaxis_title="",
        showlegend=False,
        height=min(1200, 200 + 50 * len(df_plot)),
        xaxis=dict(
            range=[start_date, end_date],
            tickmode="linear",
            dtick="M3",
            tickformat="%Y-%m",
            showgrid=True,
            gridwidth=1,
            gridcolor='rgba(128,128,128,0.5)'
        ),
        yaxis=dict(automargin=True)
    )

    st.plotly_chart(fig, use_container_width=True)

# ----------------------------------------
# â–¼ ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œéƒ¨åˆ† â–¼
# ----------------------------------------

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
deals_df, stages_df, users_df, funnel_mapping_df = load_data_with_retry()

if deals_df.empty or stages_df.empty or users_df.empty or funnel_mapping_df.empty:
    st.stop()

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
merged_df, stages_df, funnel_mapping_df = preprocess_data(deals_df, stages_df, users_df, funnel_mapping_df)

# --- Sidebar Filters ---
st.sidebar.header("ãƒ•ã‚£ãƒ«ã‚¿")

if 'å—æ³¨/å¤±æ³¨' in merged_df.columns:
    deal_status_options = ["ã™ã¹ã¦"] + list(merged_df["å—æ³¨/å¤±æ³¨"].dropna().unique())
    selected_deal_status = st.sidebar.selectbox("å—æ³¨/å¤±æ³¨", deal_status_options)
else:
    selected_deal_status = "ã™ã¹ã¦"

lead_options = ["ã™ã¹ã¦"] + list(merged_df["ãƒªãƒ¼ãƒ‰çµŒè·¯"].dropna().unique())
selected_lead_path = st.sidebar.selectbox("ãƒªãƒ¼ãƒ‰çµŒè·¯", lead_options)

new_upsell = ["ã™ã¹ã¦"] + list(merged_df["Anken Type"].dropna().unique())
selected_new_upsell = st.sidebar.selectbox("æ¡ˆä»¶ã‚¿ã‚¤ãƒ—", new_upsell)

sales_rep_options = ["ã™ã¹ã¦"] + list(merged_df["Full Name"].dropna().unique())
selected_sales_reps = st.sidebar.multiselect("å–¶æ¥­æ‹…å½“è€…", sales_rep_options, default=["ã™ã¹ã¦"])

# æ—¥ä»˜ç¯„å›²ã®é¸æŠ
date_filter_preset = st.sidebar.radio(
    "æ—¥ä»˜ç¯„å›²ã®ãƒ—ãƒªã‚»ãƒƒãƒˆ",
    ("ä»Šæœˆ","ä»Šå››åŠæœŸ", "ä»ŠåŠæœŸ", "ä»Šå¹´åº¦", "å…¨æœŸé–“","ã‚«ã‚¹ã‚¿ãƒ ")
)

today = datetime.now().date()
fiscal_year_start, fiscal_year_end, half_year_start, half_year_end, qtr_start, qtr_end, month_start, month_end = get_fiscal_dates(today)
date_col = 'Snapshot_date'
min_date_val = merged_df[date_col].min().date() if not merged_df[date_col].isna().all() else today
max_date_val = merged_df[date_col].max().date() if not merged_df[date_col].isna().all() else today

if date_filter_preset == "ä»Šæœˆ":
    start_date = month_start
    end_date = month_end
elif date_filter_preset == "ä»Šå››åŠæœŸ":
    start_date = qtr_start
    end_date = qtr_end
elif date_filter_preset == "ä»ŠåŠæœŸ":
    start_date = half_year_start
    end_date = half_year_end
elif date_filter_preset == "ä»Šå¹´åº¦":
    start_date = fiscal_year_start
    end_date = fiscal_year_end
elif date_filter_preset == "å…¨æœŸé–“":
    start_date = min_date_val
    end_date = max_date_val
else:
    start_date, end_date = st.sidebar.date_input(
        "ã‚«ã‚¹ã‚¿ãƒ æ—¥ä»˜ç¯„å›²",
        value=(min_date_val, max_date_val),
        min_value=min_date_val,
        max_value=max_date_val
    )

# --- Apply filters ---
filtered_df = merged_df.copy()

if selected_deal_status != "ã™ã¹ã¦":
    filtered_df = filtered_df[filtered_df["å—æ³¨/å¤±æ³¨"] == selected_deal_status]

if selected_lead_path != "ã™ã¹ã¦":
    filtered_df = filtered_df[filtered_df["ãƒªãƒ¼ãƒ‰çµŒè·¯"] == selected_lead_path]

if selected_new_upsell != "ã™ã¹ã¦":
    filtered_df = filtered_df[filtered_df["Anken Type"] == selected_new_upsell]

if "ã™ã¹ã¦" not in selected_sales_reps:
    filtered_df = filtered_df[filtered_df["Full Name"].isin(selected_sales_reps)]

date_col = 'Snapshot_date' if 'Snapshot_date' in filtered_df.columns else 'Create Date'
filtered_df = filtered_df[
    (filtered_df[date_col].dt.date >= start_date) & (filtered_df[date_col].dt.date <= end_date)
]


# --- Main app layout ---
st.title("HubSpot Deals ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# KPIã‚»ã‚¯ã‚·ãƒ§ãƒ³
display_kpis(filtered_df, start_date, end_date)

st.divider()

st.subheader("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰")
# debug_df = filtered_df[filtered_df['Funnel_Debug_Info'].notna()]
debug_df = filtered_df.copy()
st.warning("æ¡ˆä»¶ã®ãƒ•ã‚¡ãƒãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±")
st.dataframe(debug_df[['Deal Name', 'Anken Type', 'Stage No', 'Stagename', 'Funnel_Stage_ID', 'Funnel_Name', 'Funnel_Debug_Info']])

# ãƒ•ã‚¡ãƒãƒ«ãƒãƒ£ãƒ¼ãƒˆã¨ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’æ¨ªä¸¦ã³ã«é…ç½®
col1, col2 = st.columns(2)
with col1:
    create_funnel_chart(filtered_df, funnel_mapping_df)
with col2:
    create_monthly_bar_chart(filtered_df)
#st.write("Funnel_Name åˆ—ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤:", filtered_df["Funnel_Name"].dropna().unique())
#st.write("Funnel_Name Mappingã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤:", funnel_mapping_df["ãƒ•ã‚¡ãƒãƒ«åç§°"].unique())
st.divider()

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
create_pipeline_chart(filtered_df, start_date, end_date)
