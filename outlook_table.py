import json
import gspread
import pandas as pd
import streamlit as st
import time
from datetime import datetime, timedelta
from gspread.exceptions import APIError
from oauth2client.service_account import ServiceAccountCredentials

# --- èªè¨¼ ---
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
try:
    credentials_dict = json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)
    gc = gspread.authorize(creds)
except KeyError:
    st.error("Googleã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`st.secrets`ã«`GOOGLE_SERVICE_ACCOUNT`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- å®šæ•° ---
SPREADSHEET_KEY = "1Ra_tPm2u5K4ikxacw1vdQqY_YQg-JekMsM-ZhaaVFKg"
DEALS_SHEET = "Deals"
STAGES_SHEET = "OtherParams"
USERS_SHEET = "Users"

# --- ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼†ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰ ---
@st.cache_data(ttl=300, show_spinner="Google Sheets ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
def load_data_with_retry(max_retries=3, delay=5):
    attempt = 0
    while attempt < max_retries:
        try:
            sh = gc.open_by_key(SPREADSHEET_KEY)
            deals_ws = sh.worksheet(DEALS_SHEET)
            stages_ws = sh.worksheet(STAGES_SHEET)
            users_ws = sh.worksheet(USERS_SHEET)

            deals_data = pd.DataFrame(deals_ws.get_all_records())
            stages_data = pd.DataFrame(stages_ws.get("A2:B12"), columns=["Stage ID", "Stage Name"])
            users_data = pd.DataFrame(users_ws.get_all_records())

            return deals_data, stages_data, users_data

        except APIError as e:
            if "429" in str(e):
                st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{delay}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(delay)
                attempt += 1
            else:
                st.error(f"Google Sheets API ã‚¨ãƒ©ãƒ¼: {e}")
                break
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            break

    st.error("Google Sheetsã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¾Œã»ã©å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
    return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# --- ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•° ---
def process_and_merge_data(deals_df, stages_df, users_df):
    users_df["Full Name"] = users_df["Last Name"].fillna("") + " " + users_df["First Name"].fillna("")
    users_df = users_df.rename(columns={"ID": "User ID"})
    
    deals_df = deals_df.rename(columns={"Deal owner": "User ID", "Deal Stage": "Stage ID"})

    deals_df["User ID"] = pd.to_numeric(deals_df["User ID"], errors="coerce")
    deals_df["Stage ID"] = pd.to_numeric(deals_df["Stage ID"], errors="coerce")
    stages_df["Stage ID"] = pd.to_numeric(stages_df["Stage ID"], errors="coerce")
    
    deals_df['å—æ³¨é‡‘é¡'] = deals_df['å—æ³¨é‡‘é¡'].astype(str).str.replace(r'[^\d]', '', regex=True)
    deals_df["å—æ³¨é‡‘é¡"] = pd.to_numeric(deals_df["å—æ³¨é‡‘é¡"], errors="coerce")
    deals_df['è¦‹è¾¼å£²ä¸Šé¡'] = deals_df['è¦‹è¾¼å£²ä¸Šé¡'].astype(str).str.replace(r'[^\d]', '', regex=True)
    deals_df["è¦‹è¾¼å£²ä¸Šé¡"] = pd.to_numeric(deals_df["è¦‹è¾¼å£²ä¸Šé¡"], errors="coerce")
    
    merged_df = deals_df.merge(users_df[["User ID", "Full Name"]], on="User ID", how="left")
    merged_df = merged_df.merge(stages_df, on="Stage ID", how="left")
    
    return merged_df

# --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºé–¢æ•° ---
def display_pipeline_projects_table(df):
    """
    ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ã®ä¸€è¦§ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚
    """
    st.subheader("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ä¸€è¦§")

    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    df['å—æ³¨ç›®æ¨™æ—¥_dt'] = pd.to_datetime(df['å—æ³¨ç›®æ¨™æ—¥'], errors='coerce')
    df['ç´å“äºˆå®šæ—¥_dt'] = pd.to_datetime(df['ç´å“äºˆå®šæ—¥'], errors='coerce')

    # ç¾åœ¨ã®æ—¥ä»˜ã‚’å–å¾—
    today = datetime.now()

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: å—æ³¨ç›®æ¨™æ—¥ãŒæœªæ¥ã®æ¡ˆä»¶ã€ã¾ãŸã¯ç´å“äºˆå®šæ—¥ãŒæœªæ¥ã®æ¡ˆä»¶
    df_pipeline = df[(df['å—æ³¨ç›®æ¨™æ—¥_dt'] > today) | (df['ç´å“äºˆå®šæ—¥_dt'] > today)].copy()

    if df_pipeline.empty:
        st.info("æœªæ¥ã®å—æ³¨ç›®æ¨™æ—¥ã¾ãŸã¯ç´å“äºˆå®šæ—¥ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # è¡¨ç¤ºç”¨ã«ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_df = df_pipeline.rename(columns={
        'Full Name': 'å–¶æ¥­æ‹…å½“è€…',
        'Deal Name': 'æ¡ˆä»¶å',
        'Stage Name': 'ãƒ•ã‚§ãƒ¼ã‚º'
    })

    # è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ
    cols_to_display = [
        'å–¶æ¥­æ‹…å½“è€…',
        'æ¡ˆä»¶å',
        'å—æ³¨ç›®æ¨™æ—¥_dt',
        'ç´å“äºˆå®šæ—¥_dt',
        'ãƒ•ã‚§ãƒ¼ã‚º',
        'è¦‹è¾¼å£²ä¸Šé¡',
        'å—æ³¨é‡‘é¡'
    ]
    display_df = display_df[cols_to_display]

    # æ—¥ä»˜åˆ—ã‚’'YYYY-MM-DD'å½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›
    display_df['å—æ³¨ç›®æ¨™æ—¥'] = display_df['å—æ³¨ç›®æ¨™æ—¥_dt'].dt.strftime('%Y-%m-%d').fillna('')
    display_df['ç´å“äºˆå®šæ—¥'] = display_df['ç´å“äºˆå®šæ—¥_dt'].dt.strftime('%Y-%m-%d').fillna('')
    
    # --- æ‹…å½“è€…ã”ã¨ã®è¡¨ç¤º ---
    st.subheader("å–¶æ¥­æ‹…å½“è€…åˆ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    
    # æ‹…å½“è€…ã”ã¨ã®ã‚½ãƒ¼ãƒˆã¨è¡¨ç¤º
    sorted_by_user_df = display_df.sort_values(
        by=['å–¶æ¥­æ‹…å½“è€…', 'å—æ³¨ç›®æ¨™æ—¥_dt', 'å—æ³¨é‡‘é¡'], 
        ascending=[True, True, False],
        na_position='last'
    )
    grouped_by_user = sorted_by_user_df.groupby('å–¶æ¥­æ‹…å½“è€…')

    # æ‹…å½“è€…ã”ã¨ã®è¡¨ç¤ºéƒ¨åˆ†
    with st.expander(f"å–¶æ¥­æ‹…å½“è€…: {name}"):
        st.dataframe(
            group.drop(columns=['å—æ³¨ç›®æ¨™æ—¥_dt', 'ç´å“äºˆå®šæ—¥_dt']), 
            use_container_width=True, 
            height=300 # ğŸ‘ˆ ã“ã®è¡Œã‚’è¿½åŠ 
        )
        total_outlook = group['è¦‹è¾¼å£²ä¸Šé¡'].sum()
        st.markdown(f"***åˆè¨ˆå£²ä¸Šè¦‹è¾¼é¡: {total_outlook:,.0f}***")

    # --- æœˆã”ã¨ã®è¡¨ç¤º ---
    st.subheader("æœˆåˆ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    
    # æœˆã”ã¨ã®ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
    next_month = (today.replace(day=1) + timedelta(days=32)).replace(day=1)
    two_months_later = (today.replace(day=1) + timedelta(days=62)).replace(day=1)

    def get_month_group(date):
        if pd.isna(date):
            return "ãã®ä»–"
        if date.year == today.year and date.month == today.month:
            return "ä»Šæœˆ"
        elif date.year == next_month.year and date.month == next_month.month:
            return "æ¥æœˆ"
        elif date.year == two_months_later.year and date.month == two_months_later.month:
            return "å†æ¥æœˆ"
        else:
            return "ãã®ä»–"
    
    # 'å—æ³¨ç›®æ¨™æ—¥_dt'åˆ—ã‚’ä½¿ã£ã¦ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ç”¨ã®æ–°ã—ã„åˆ—ã‚’ä½œæˆ
    display_df['Grouping Month'] = display_df['å—æ³¨ç›®æ¨™æ—¥_dt'].apply(get_month_group)

    # æ–°ã—ã„åˆ—ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    grouped_by_month = display_df.groupby('Grouping Month')
    # æœˆã”ã¨ã®è¡¨ç¤ºéƒ¨åˆ†
    with st.expander(f"{name}"):
        st.dataframe(
            group2.drop(columns=['å—æ³¨ç›®æ¨™æ—¥_dt', 'ç´å“äºˆå®šæ—¥_dt']), 
            use_container_width=True, 
            height=300 # ğŸ‘ˆ ã“ã®è¡Œã‚’è¿½åŠ 
    )
    total_outlook2 = group2['è¦‹è¾¼å£²ä¸Šé¡'].sum()
    st.markdown(f"***åˆè¨ˆå£²ä¸Šè¦‹è¾¼é¡: {total_outlook2:,.0f}***")
            
# --- ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œéƒ¨åˆ† ---
def main():
    st.title("HubSpot Deals ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    deals_df, stages_df, users_df = load_data_with_retry()
    if deals_df.empty or stages_df.empty or users_df.empty:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢ã—ã¾ã™ã€‚")
        st.stop()

    merged_df = process_and_merge_data(deals_df, stages_df, users_df)

    display_pipeline_projects_table(merged_df)

if __name__ == "__main__":
    main()
