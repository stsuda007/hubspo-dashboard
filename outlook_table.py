import json
import gspread
import pandas as pd
import streamlit as st
import time
from datetime import datetime, timedelta
from gspread.exceptions import APIError
from oauth2client.service_account import ServiceAccountCredentials
st.set_page_config(
    page_title="Hubspot Dashboard",
    page_icon="ğŸ§Š",
    layout="wide",# streamlitãŒç”»é¢ã„ã£ã±ã„ã«ä½¿ã†
    initial_sidebar_state="expanded",
    menu_items={
        'Under Construction': 'https://appspo-dashboard-wvlcv5imdrc8mo8o3aswnp.streamlit.app/',
        'Menu-2': "https://appspo-dashboard-wvlcv5imdrc8mo8o3aswnp.streamlit.app/",
        'About': "# This is a header. This is an *extremely* cool app!"
    }
)

# --- èªè¨¼ ---
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
try:
    credentials_dict = json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)
    gc = gspread.authorize(creds)
except KeyError:
    st.error("Googleã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`st.secrets`ã«`GOOGLE_SERVICE_ACCOUNT`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()
# ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚­ãƒ¼ã‚’ã€st.secretsã‹ã‚‰èª­ã¿è¾¼ã‚€ã‚ˆã†ã«å¤‰æ›´
try:
    SPREADSHEET_KEY = st.secrets["SPREADSHEET_KEY"]
except KeyError:
    st.error("Google Sheetsã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`st.secrets`ã«`SPREADSHEET_KEY`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- å®šæ•° ---
#SPREADSHEET_KEY = "1Ra_tPm2u5K4ikxacw1vdQqY_YQg-JekMsM-ZhaaVFKg"
DEALS_SHEET = "Deals"
STAGES_SHEET = "OtherParams"
USERS_SHEET = "Users"

# --- ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼†ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰ ---
@st.cache_data(ttl=300, show_spinner="Google Sheets ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
def load_data_with_retry(max_retries=3, delay=5):
    attempt = 0
    while attempt < max_retries:
        try:
            sh = gc.open_by_key(SPREADSHEET_KEY)
            deals_ws = sh.worksheet(DEALS_SHEET)
            stages_ws = sh.worksheet(STAGES_SHEET)
            users_ws = sh.worksheet(USERS_SHEET)

            deals_data = pd.DataFrame(deals_ws.get_all_records())
            stages_data = pd.DataFrame(stages_ws.get("A2:B12"), columns=["Stage ID", "Stage Name"])
            users_data = pd.DataFrame(users_ws.get_all_records())

            return deals_data, stages_data, users_data

        except APIError as e:
            if "429" in str(e):
                st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{delay}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(delay)
                attempt += 1
            else:
                st.error(f"Google Sheets API ã‚¨ãƒ©ãƒ¼: {e}")
                break
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            break

    st.error("Google Sheetsã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¾Œã»ã©å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
    return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# --- ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•° ---
def process_and_merge_data(deals_df, stages_df, users_df):
    users_df["Full Name"] = users_df["Last Name"].fillna("") + " " + users_df["First Name"].fillna("")
    users_df = users_df.rename(columns={"ID": "User ID"})
    
    deals_df = deals_df.rename(columns={"Deal owner": "User ID", "Deal Stage": "Stage ID"})

    deals_df["User ID"] = pd.to_numeric(deals_df["User ID"], errors="coerce")
    deals_df["Stage ID"] = pd.to_numeric(deals_df["Stage ID"], errors="coerce")
    stages_df["Stage ID"] = pd.to_numeric(stages_df["Stage ID"], errors="coerce")
    
    # é‡‘é¡ã‚«ãƒ©ãƒ ã®å‰å‡¦ç†ã‚’å¼·åŒ–
    deals_df['å—æ³¨é‡‘é¡'] = deals_df['å—æ³¨é‡‘é¡'].astype(str).str.replace(r'[^\d]', '', regex=True)
    deals_df["å—æ³¨é‡‘é¡"] = pd.to_numeric(deals_df["å—æ³¨é‡‘é¡"], errors="coerce")
    deals_df['è¦‹è¾¼å£²ä¸Šé¡'] = deals_df['è¦‹è¾¼å£²ä¸Šé¡'].astype(str).str.replace(r'[^\d]', '', regex=True)
    deals_df["è¦‹è¾¼å£²ä¸Šé¡"] = pd.to_numeric(deals_df["è¦‹è¾¼å£²ä¸Šé¡"], errors="coerce")
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°å†…ã§ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®åˆ—ã‚’ç”Ÿæˆ
    deals_df['è¦‹è¾¼å£²ä¸Šé¡ï¼ˆå††ï¼‰'] = deals_df['è¦‹è¾¼å£²ä¸Šé¡'].apply(lambda x: f"ï¿¥{x:,.0f}" if pd.notna(x) else "")
    deals_df['å—æ³¨é‡‘é¡ï¼ˆå††ï¼‰'] = deals_df['å—æ³¨é‡‘é¡'].apply(lambda x: f"ï¿¥{x:,.0f}" if pd.notna(x) else "")
    
    merged_df = deals_df.merge(users_df[["User ID", "Full Name"]], on="User ID", how="left")
    merged_df = merged_df.merge(stages_df, on="Stage ID", how="left")
    
    return merged_df

# --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºé–¢æ•° ---
def display_pipeline_projects_table(df):
    """
    ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ã®ä¸€è¦§ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚
    """
    #st.subheader("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ä¸€è¦§")

    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    df['å—æ³¨ç›®æ¨™æ—¥_dt'] = pd.to_datetime(df['å—æ³¨ç›®æ¨™æ—¥'], errors='coerce')
    df['ç´å“äºˆå®šæ—¥_dt'] = pd.to_datetime(df['ç´å“äºˆå®šæ—¥'], errors='coerce')

    # ç¾åœ¨ã®æ—¥ä»˜ã‚’å–å¾—
    today = datetime.now()
    first_day_of_current_month = today.replace(day=1)

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: å—æ³¨ç›®æ¨™æ—¥ã¾ãŸã¯ç´å“äºˆå®šæ—¥ãŒä»Šæœˆä»¥é™ã®æ¡ˆä»¶
    df_pipeline = df[(df['å—æ³¨ç›®æ¨™æ—¥_dt'] >= first_day_of_current_month) | (df['ç´å“äºˆå®šæ—¥_dt'] >= first_day_of_current_month)].copy()
    if df_pipeline.empty:
        st.info("ä»Šæœˆä»¥é™ã®å—æ³¨ç›®æ¨™æ—¥ã¾ãŸã¯ç´å“äºˆå®šæ—¥ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # è¡¨ç¤ºç”¨ã«ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_df = df_pipeline.rename(columns={
        'Full Name': 'å–¶æ¥­æ‹…å½“è€…',
        'Deal Name': 'æ¡ˆä»¶å',
        'Stage Name': 'ãƒ•ã‚§ãƒ¼ã‚º'
    })

    # `cols_to_display`ã§åˆ—ã®é †åºã‚’çµ±ä¸€
    cols_to_display = [
        'å–¶æ¥­æ‹…å½“è€…',
        'æ¡ˆä»¶å',
        'å—æ³¨ç›®æ¨™æ—¥_dt',
        'ç´å“äºˆå®šæ—¥_dt',
        'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆå††ï¼‰',
        'å—æ³¨é‡‘é¡ï¼ˆå††ï¼‰',
        'ãƒ•ã‚§ãƒ¼ã‚º',
        'è¦‹è¾¼å£²ä¸Šé¡', # å…ƒã®é‡‘é¡åˆ—
        'å—æ³¨é‡‘é¡' # å…ƒã®é‡‘é¡åˆ—
    ]
    display_df = display_df[cols_to_display]

    # --- æœˆã”ã¨ã®è¡¨ç¤º ---
    st.subheader("æœˆåˆ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    next_month = (today.replace(day=1) + timedelta(days=32)).replace(day=1)
    two_months_later = (today.replace(day=1) + timedelta(days=62)).replace(day=1)
    three_months_later = (today.replace(day=1) + timedelta(days=93)).replace(day=1)

    def get_month_group(date):
        if pd.isna(date):
            return "ãã®ä»–"
        if date.year == today.year and date.month == today.month:
            return f"{today.month}æœˆ"
        elif date.year == next_month.year and date.month == next_month.month:
            return f"{next_month.month}æœˆ"
        elif date.year == two_months_later.year and date.month == two_months_later.month:
            return f"{two_months_later.month}æœˆ"
        elif date.year == three_months_later.year and date.month == three_months_later.month:
            return f"{three_months_later.month}æœˆ"
        else:
            return "ãã®ä»–"

    display_df['Grouping Month'] = display_df['å—æ³¨ç›®æ¨™æ—¥_dt'].apply(get_month_group)
    grouped_by_month = display_df.groupby('Grouping Month')
    current_month_name = f"{today.month}æœˆ"
    next_month_name = f"{next_month.month}æœˆ"
    two_months_later_name = f"{two_months_later.month}æœˆ"
    three_months_later_name = f"{three_months_later.month}æœˆ"
    custom_order = [current_month_name, next_month_name, two_months_later_name, three_months_later_name, "ãã®ä»–"]
    sorted_groups = sorted(grouped_by_month, key=lambda x: custom_order.index(x[0]) if x[0] in custom_order else 99)

    # è¡¨ç¤ºã™ã‚‹åˆ—ã®é †åºã‚’å®šç¾©
    display_columns = ('å–¶æ¥­æ‹…å½“è€…', 'æ¡ˆä»¶å', 'å—æ³¨ç›®æ¨™æ—¥_dt', 'ç´å“äºˆå®šæ—¥_dt', 'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆå††ï¼‰', 'å—æ³¨é‡‘é¡ï¼ˆå††ï¼‰', 'ãƒ•ã‚§ãƒ¼ã‚º')
    for name, group2 in sorted_groups:
        total_outlook2 = group2['è¦‹è¾¼å£²ä¸Šé¡'].sum()
        with st.expander(f"{name} ãƒ¼ å£²ä¸Šè¦‹è¾¼é¡: {total_outlook2:,.0f}"):
            sorted_group2 = group2.sort_values(
                by='å—æ³¨ç›®æ¨™æ—¥_dt',
                ascending=True,
                na_position='last'
            ).copy()
            
            st.dataframe(
                sorted_group2.drop(columns=['Grouping Month']),
                column_config={
                    "è¦‹è¾¼å£²ä¸Šé¡ï¼ˆå††ï¼‰": st.column_config.TextColumn(
                        "è¦‹è¾¼å£²ä¸Šé¡",
                        help="æ¡ˆä»¶ã®äºˆæƒ³å£²ä¸Šé‡‘é¡"
                    ),
                    "å—æ³¨é‡‘é¡ï¼ˆå††ï¼‰": st.column_config.TextColumn(
                        "å—æ³¨é‡‘é¡",
                        help="å—æ³¨ãŒç¢ºå®šã—ãŸé‡‘é¡"
                    ),
                    "å—æ³¨ç›®æ¨™æ—¥_dt": st.column_config.DateColumn(
                        "å—æ³¨ç›®æ¨™æ—¥",
                        help="å—æ³¨ã®ç›®æ¨™æ—¥",
                        format="MM/DD",
                    ),
                    "ç´å“äºˆå®šæ—¥_dt": st.column_config.DateColumn(
                        "ç´å“äºˆå®šæ—¥",
                        help="ç´å“ã®äºˆå®šæ—¥",
                        format="MM/DD",
                    ),
                },
                hide_index=True,
                use_container_width=True,
                height=300,
                #hide_columns=['è¦‹è¾¼å£²ä¸Šé¡', 'å—æ³¨é‡‘é¡']
                column_order=display_columns # ã“ã“ã« column_order ã‚’è¿½åŠ 
            )
            # st.markdownã®è¡¨ç¤ºã‚‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¡¨ç¤º
            st.markdown(f"***åˆè¨ˆå£²ä¸Šè¦‹è¾¼é¡: {total_outlook2:,.0f}***")

    # --- æ‹…å½“è€…ã”ã¨ã®è¡¨ç¤º ---
    st.subheader("å–¶æ¥­æ‹…å½“è€…åˆ¥ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    
    # æ‹…å½“è€…ã”ã¨ã®ã‚½ãƒ¼ãƒˆã¨ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    sorted_by_user_df = display_df.sort_values(
        by=['å–¶æ¥­æ‹…å½“è€…', 'å—æ³¨ç›®æ¨™æ—¥_dt'],
        ascending=[True, True],
        na_position='last'
    )
    grouped_by_user = sorted_by_user_df.groupby('å–¶æ¥­æ‹…å½“è€…')

    # å„æ‹…å½“è€…ã®ãƒ‡ãƒ¼ã‚¿ã‚’å€‹åˆ¥ã«è¡¨ç¤º
    for name, group in grouped_by_user:
        with st.expander(f"{name} ãƒ¼ æ¡ˆä»¶æ•°:{group.shape[0]}"):
            st.dataframe(
                group.drop(columns=['Grouping Month']),
                column_config={
                    "è¦‹è¾¼å£²ä¸Šé¡ï¼ˆå††ï¼‰": st.column_config.TextColumn(
                        "è¦‹è¾¼å£²ä¸Šé¡",
                        help="æ¡ˆä»¶ã®äºˆæƒ³å£²ä¸Šé‡‘é¡"
                    ),
                    "å—æ³¨é‡‘é¡ï¼ˆå††ï¼‰": st.column_config.TextColumn(
                        "å—æ³¨é‡‘é¡",
                        help="å—æ³¨ãŒç¢ºå®šã—ãŸé‡‘é¡"
                    ),
                    "å—æ³¨ç›®æ¨™æ—¥_dt": st.column_config.DateColumn(
                        "å—æ³¨ç›®æ¨™æ—¥",
                        help="å—æ³¨ã®ç›®æ¨™æ—¥",
                        format="MM/DD",
                    ),
                    "ç´å“äºˆå®šæ—¥_dt": st.column_config.DateColumn(
                        "ç´å“äºˆå®šæ—¥",
                        help="ç´å“ã®äºˆå®šæ—¥",
                        format="MM/DD",
                    ),
                },
                use_container_width=True,
                height=300,
                hide_index=True,
                #hide_columns=['è¦‹è¾¼å£²ä¸Šé¡', 'å—æ³¨é‡‘é¡']
                column_order=display_columns # ã“ã“ã« column_order ã‚’è¿½åŠ 
            )
            total_sum = group['å—æ³¨é‡‘é¡'].sum()
            total_outlook = group['è¦‹è¾¼å£²ä¸Šé¡'].sum()
            st.markdown(f"**åˆè¨ˆå—æ³¨é‡‘é¡: {total_sum:,.0f}ã€€åˆè¨ˆå£²ä¸Šè¦‹è¾¼é¡: {total_outlook:,.0f}**")

# --- ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œéƒ¨åˆ† ---
def main():
    #st.title("HubSpot Deals ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.markdown(f'<h2 style="color:#444444;font-size:24px;">{"å—æ³¨ç›®æ¨™ã®ã‚ã‚‹æ¡ˆä»¶ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"}</h1>', unsafe_allow_html=True)
    deals_df, stages_df, users_df = load_data_with_retry()
    if deals_df.empty or stages_df.empty or users_df.empty:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢ã—ã¾ã™ã€‚")
        st.stop()
    merged_df = process_and_merge_data(deals_df, stages_df, users_df)
    display_pipeline_projects_table(merged_df)

if __name__ == "__main__":
    main()
