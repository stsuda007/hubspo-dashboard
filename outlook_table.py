import time
import json
import gspread
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import APIError

# --- Authentication ---
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
try:
    credentials_dict = json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)
    gc = gspread.authorize(creds)
except KeyError:
    st.error("Googleã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`st.secrets`ã«`GOOGLE_SERVICE_ACCOUNT`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- Spreadsheet settings ---
SPREADSHEET_KEY = "1Ra_tPm2u5K4ikxacw1vdQqY_YQg-JekMsM-ZhaaVFKg"
DEALS_SHEET = "Deals"
STAGES_SHEET = "OtherParams"
USERS_SHEET = "Users"

# --- Data fetching function (cached & with retry) ---
@st.cache_data(ttl=300, show_spinner="Google Sheets ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
def load_data_with_retry(max_retries=3, delay=5):
    """
    Fetches data from Google Sheets and retries if an API rate limit is reached.
    """
    attempt = 0
    while attempt < max_retries:
        try:
            deals_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(DEALS_SHEET)
            stages_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(STAGES_SHEET)
            users_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(USERS_SHEET)

            deals_data = pd.DataFrame(deals_ws.get_all_records())
            stages_data = pd.DataFrame(stages_ws.get("A2:B12"), columns=["Stage ID", "Stage Name"])
            users_data = pd.DataFrame(users_ws.get_all_records())
            return deals_data, stages_data, users_data

        except APIError as e:
            if "429" in str(e):
                st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{delay}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(delay)
                attempt += 1
            else:
                st.error(f"Google Sheets API ã‚¨ãƒ©ãƒ¼: {e}")
                break

    st.error("Google Sheetsã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¾Œã»ã©å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
    return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# --- Load data ---
deals_df, stages_df, users_df = load_data_with_retry()

if deals_df.empty:
    st.stop()

# --- Convert IDs to names ---
users_df["Full Name"] = users_df["First Name"].fillna("") + " " + users_df["Last Name"].fillna("")
users_df = users_df.rename(columns={"ID": "User ID"})
deals_df = deals_df.rename(columns={"Deal owner": "User ID", "Deal Stage": "Stage ID"})

# Convert columns to numeric safely
deals_df["User ID"] = pd.to_numeric(deals_df["User ID"], errors="coerce")
deals_df["Stage ID"] = pd.to_numeric(deals_df["Stage ID"], errors="coerce")
stages_df["Stage ID"] = pd.to_numeric(stages_df["Stage ID"], errors="coerce")

# 'å—æ³¨é‡‘é¡'åˆ—ã‹ã‚‰éæ•°å€¤æ–‡å­—ï¼ˆã‚«ãƒ³ãƒã€å…¨è§’æ•°å­—ãªã©ï¼‰ã‚’å‰Šé™¤ã—ã€æ•°å€¤ã«å¤‰æ›
deals_df['å—æ³¨é‡‘é¡'] = deals_df['å—æ³¨é‡‘é¡'].astype(str).str.replace(r'[^\d]', '', regex=True)
deals_df["å—æ³¨é‡‘é¡"] = pd.to_numeric(deals_df["å—æ³¨é‡‘é¡"], errors="coerce")

# é‡‘é¡ã‚’10000ã§å‰²ã£ã¦åˆ‡ã‚Šæ¨ã¦ã‚‹å‰ã«ã€NaNã‚’0ã«ç½®ãæ›ãˆã‚‹
deals_df["å—æ³¨é‡‘é¡"] = (deals_df["å—æ³¨é‡‘é¡"] / 10000).fillna(0).astype(int)

merged_df = deals_df.merge(users_df[["User ID", "Full Name"]], on="User ID", how="left")
merged_df = merged_df.merge(stages_df, on="Stage ID", how="left")

# --- Function to create the deals pipeline chart ---
def pipeline_chart_juchu(df):
    """
    Creates a pipeline chart for 'å—æ³¨' (won) deals from the start of the first negotiation to the closing date.
    """
    st.title("HubSpot Deals ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.subheader("å—æ³¨æ¡ˆä»¶ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ")
    st.write("å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°:", len(df))

    # Filter data for 'å—æ³¨' (won) deals only
    df_filtered = df[(df['å—æ³¨/å¤±æ³¨'] == 'å—æ³¨')].copy()
    st.write("å—æ³¨ãƒ•ãƒ©ã‚°ã®ãƒ‡ãƒ¼ã‚¿æ•°:", len(df_filtered))

    # Convert date columns to datetime objects
    date_columns = ['åˆå›å•†è«‡å®Ÿæ–½æ—¥', 'å—æ³¨æ—¥', 'å—æ³¨ç›®æ¨™æ—¥', 'æœ‰å„Ÿãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç™ºè¡Œ', 'æ¦‚ç®—è¦‹ç©æå‡ºæ—¥', 'å ±å‘Š/ææ¡ˆæ—¥','æœ€çµ‚è¦‹ç©æå‡ºæ—¥', 'Create Date']
    for col in date_columns:
        if col in df_filtered.columns:
            df_filtered[col] = pd.to_datetime(df_filtered[col], errors='coerce')
    
    # ã‚°ãƒ©ãƒ•ã®çµ‚ç‚¹ã§ã‚ã‚‹å—æ³¨æ—¥ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤
    df_filtered = df_filtered.dropna(subset=['å—æ³¨æ—¥'])
    st.write("å—æ³¨æ—¥ä¸è¨˜è¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿æ•°:", len(df_filtered))
    
    # åˆå›å•†è«‡å®Ÿæ–½æ—¥ãŒç©ºæ¬„ã®å ´åˆã®ãƒ•ãƒ©ã‚°ã‚’ä½œæˆ
    df_filtered['is_start_date_fallback'] = df_filtered['åˆå›å•†è«‡å®Ÿæ–½æ—¥'].isna()
    st.write("åˆå›å•†è«‡å®Ÿæ–½æ—¥ä¸è¨˜è¼‰ã®ãƒ‡ãƒ¼ã‚¿æ•°:", df_filtered['is_start_date_fallback'].sum())

    # åˆå›å•†è«‡å®Ÿæ–½æ—¥ãŒç©ºæ¬„ã®å ´åˆã¯Create Dateã§è£œå®Œ
    df_filtered['åˆå›å•†è«‡å®Ÿæ–½æ—¥'] = df_filtered['åˆå›å•†è«‡å®Ÿæ–½æ—¥'].fillna(df_filtered['Create Date'])
    
    if df_filtered.empty:
        st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å—æ³¨æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # Create a DataFrame for plotting
    df_plot = df_filtered.copy()
    
    # æ¡ˆä»¶åã«ãƒªãƒ¼ãƒ‰çµŒè·¯ã‚’è¿½åŠ 
    df_plot['æ¡ˆä»¶å'] = df_plot['Deal Name'] + '<br>' + '(' + df_plot['ãƒªãƒ¼ãƒ‰çµŒè·¯'] + ')'
    df_plot['Start'] = df_plot['åˆå›å•†è«‡å®Ÿæ–½æ—¥']
    df_plot['Finish'] = df_plot['å—æ³¨æ—¥']
    
    # ã‚°ãƒ©ãƒ•ã®å§‹ç‚¹ï¼ˆStartï¼‰ã¨çµ‚ç‚¹ï¼ˆFinishï¼‰ã®ä¸¡æ–¹ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    df_plot = df_plot.dropna(subset=['Start', 'Finish'])
    st.write("æœ€çµ‚çš„ãªã‚°ãƒ©ãƒ•è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿æ•°:", len(df_plot))

    if df_plot.empty:
        st.info("ãƒ—ãƒ­ãƒƒãƒˆå¯èƒ½ãªå—æ³¨æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    df_plot = df_plot.sort_values('Start')

    # Create the Plotly Gantt chart
    fig = go.Figure()

    # Add markers and connecting lines for each deal
    for index, row in df_plot.iterrows():
        # Add a line connecting the start and end points (no hover info on the line itself)
        fig.add_trace(go.Scatter(
            x=[row['Start'], row['Finish']],
            y=[row['æ¡ˆä»¶å'], row['æ¡ˆä»¶å']],
            mode='lines',
            line=dict(color='black', width=3),
            showlegend=False,
            hoverinfo='none' # Changed to 'none' as hoverinfo on lines is not ideal
        ))

        # Add a marker for the start date (blue circle)
        # åˆå›å•†è«‡å®Ÿæ–½æ—¥ãŒç©ºæ¬„ã ã£ãŸå ´åˆã¯ã‚°ãƒ¬ãƒ¼ã®ãƒãƒ¼ã‚«ãƒ¼ã§è¡¨ç¤º
        marker_color = 'grey' if row['is_start_date_fallback'] else 'blue'
        start_date_label = "æ¡ˆä»¶ä½œæˆæ—¥" if row['is_start_date_fallback'] else "åˆå›å•†è«‡å®Ÿæ–½æ—¥"
        
        fig.add_trace(go.Scatter(
            x=[row['Start']],
            y=[row['æ¡ˆä»¶å']],
            mode='markers',
            marker=dict(color=marker_color, size=10, symbol='circle'),
            name=f"{row['æ¡ˆä»¶å']} ({start_date_label})",
            showlegend=False,
            hoverinfo='text',
            hovertext=f"æ¡ˆä»¶å: {row['Deal Name']}<br>å–¶æ¥­æ‹…å½“:{row['Full Name']}<br>æ—¥ä»˜: {row['Start'].strftime('%Y-%m-%d')}<br>ç¨®åˆ¥: {start_date_label}"
        ))

        # Add a marker for the end date (red circle) with text for the amount
        fig.add_trace(go.Scatter(
            x=[row['Finish']],
            y=[row['æ¡ˆä»¶å']],
            mode='markers+text',
            marker=dict(color='red', size=10, symbol='circle'),
            text=[f"{row['å—æ³¨é‡‘é¡']:,}ä¸‡å††"],
            textposition="middle right",
            name=f"{row['æ¡ˆä»¶å']} (å—æ³¨æ—¥)",
            showlegend=False,
            hoverinfo='text',
            hovertext=f"æ¡ˆä»¶å: {row['Deal Name']}<br>é‡‘é¡: {row['å—æ³¨é‡‘é¡']:,}ä¸‡å††"
        ))
        
        # Add markers for 'å ±å‘Š/ææ¡ˆæ—¥' (if they exist)
        if 'å ±å‘Š/ææ¡ˆæ—¥' in df_plot.columns and pd.notna(row['å ±å‘Š/ææ¡ˆæ—¥']):
            fig.add_trace(go.Scatter(
                x=[row['å ±å‘Š/ææ¡ˆæ—¥']],
                y=[row['æ¡ˆä»¶å']],
                mode='markers',
                marker=dict(color='rgba(0, 0, 0, 0)', size=7, symbol='circle', line=dict(color='green', width=2)),
                name=f"{row['æ¡ˆä»¶å']} (å ±å‘Š/ææ¡ˆ)",
                showlegend=False,
                hoverinfo='text',
                hovertext=f"å ±å‘Š/ææ¡ˆæ—¥: {row['å ±å‘Š/ææ¡ˆæ—¥'].strftime('%Y-%m-%d')}"
            ))
        # Add markers for 'æ¦‚ç®—è¦‹ç©æå‡ºæ—¥' (if they exist)
        if 'æ¦‚ç®—è¦‹ç©æå‡ºæ—¥' in df_plot.columns and pd.notna(row['æ¦‚ç®—è¦‹ç©æå‡ºæ—¥']):
            fig.add_trace(go.Scatter(
                x=[row['æ¦‚ç®—è¦‹ç©æå‡ºæ—¥']],
                y=[row['æ¡ˆä»¶å']],
                mode='markers',
                marker=dict(color='rgba(0, 0, 0, 0)', size=7, symbol='circle', line=dict(color='green', width=2)),
                name=f"{row['æ¡ˆä»¶å']} (æ¦‚ç®—è¦‹ç©æå‡ºæ—¥)",
                showlegend=False,
                hoverinfo='text',
                hovertext=f"æ¦‚ç®—è¦‹ç©æå‡ºæ—¥: {row['æ¦‚ç®—è¦‹ç©æå‡ºæ—¥'].strftime('%Y-%m-%d')}"
            ))

    fig.update_layout(
        title="å—æ³¨æ¡ˆä»¶ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆåˆå›å•†è«‡æ—¥ã€œå—æ³¨æ—¥ï¼‰",
        xaxis_title="å¹´æœˆ",
        yaxis_title="",
        showlegend=False,
        # ã‚°ãƒ©ãƒ•ã®é«˜ã•ã‚’å‹•çš„ã«èª¿æ•´
        height=400 + 50 * len(df_plot),
        xaxis=dict(
            range=[datetime(2024, 1, 1), datetime(2025, 12, 31)],
            tickmode="linear",
            dtick="M3",
            tickformat="%Y-%m",
            showgrid=True,
            gridwidth=1,
            gridcolor='rgba(128,128,128,0.5)'
        ),
        # Yè»¸ã®æ–‡å­—ã‚’2è¡Œã«æŠ˜ã‚Šè¿”ã™ã‚ˆã†ã«è¨­å®š
        yaxis=dict(automargin=True)
    )

    st.plotly_chart(fig, use_container_width=True)

# --- NEW: Pipeline Projects Table Function ---
def table_of_pipeline_projects(df):
    """
    ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ï¼ˆå—æ³¨ç›®æ¨™æ—¥ã¾ãŸã¯ç´å“äºˆå®šæ—¥ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æ¡ˆä»¶ï¼‰ã‚’è¡¨ç¤º
    """
    st.subheader("ğŸ“Š ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ä¸€è¦§")
    
    # æ—¥ä»˜åˆ—ã‚’å¤‰æ›
    date_cols = ['å—æ³¨ç›®æ¨™æ—¥', 'ç´å“äºˆå®šæ—¥']
    for col in date_cols:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ä»¶: å—æ³¨ç›®æ¨™æ—¥ã¾ãŸã¯ç´å“äºˆå®šæ—¥ã®ã„ãšã‚Œã‹ãŒå­˜åœ¨
    pipeline_condition = (
        df['å—æ³¨ç›®æ¨™æ—¥'].notna() | 
        df['ç´å“äºˆå®šæ—¥'].notna()
    )
    
    df_pipeline = df[pipeline_condition].copy()
    
    if df_pipeline.empty:
        st.info("å—æ³¨ç›®æ¨™æ—¥ã¾ãŸã¯ç´å“äºˆå®šæ—¥ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    display_df = df_pipeline.copy()
    
    # å¿…è¦ãªåˆ—ã‚’é¸æŠãƒ»ãƒªãƒãƒ¼ãƒ 
    columns_to_show = {
        'Full Name': 'å–¶æ¥­æ‹…å½“è€…',
        'Deal Name': 'æ¡ˆä»¶å', 
        'å—æ³¨é‡‘é¡': 'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰'
    }
    
    # Deal TypeãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if 'Deal Type' in display_df.columns:
        columns_to_show['Deal Type'] = 'Deal Type'
    
    # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’ä½¿ç”¨
    available_columns = {k: v for k, v in columns_to_show.items() if k in display_df.columns}
    
    if not available_columns:
        st.error("å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    result_df = display_df[list(available_columns.keys())].rename(columns=available_columns)
    
    # æ—¥ä»˜æƒ…å ±ã‚’è¿½åŠ 
    def format_dates(row):
        dates = []
        if pd.notna(row['å—æ³¨ç›®æ¨™æ—¥']):
            dates.append(f"å—æ³¨ç›®æ¨™: {row['å—æ³¨ç›®æ¨™æ—¥'].strftime('%Y-%m-%d')}")
        if pd.notna(row['ç´å“äºˆå®šæ—¥']):
            dates.append(f"ç´å“äºˆå®š: {row['ç´å“äºˆå®šæ—¥'].strftime('%Y-%m-%d')}")
        return " / ".join(dates) if dates else ""
    
    result_df['äºˆå®šæ—¥'] = display_df.apply(format_dates, axis=1)
    
    # NaNå€¤ã‚’é©åˆ‡ã«å‡¦ç†
    result_df = result_df.fillna({
        'å–¶æ¥­æ‹…å½“è€…': 'æœªè¨­å®š',
        'Deal Type': 'æœªè¨­å®š',
        'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰': 0
    })
    
    # ã‚½ãƒ¼ãƒˆ
    sort_columns = ['å–¶æ¥­æ‹…å½“è€…']
    if 'Deal Type' in result_df.columns:
        sort_columns.append('Deal Type')
    sort_columns.append('è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰')
    
    result_df = result_df.sort_values(sort_columns, ascending=[True, True, False] if len(sort_columns) == 3 else [True, False])
    
    # ãƒ¡ã‚¤ãƒ³è¡¨ç¤º
    st.write(f"**ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶æ•°: {len(result_df)}ä»¶**")
    st.dataframe(result_df, use_container_width=True)
    
    # å–¶æ¥­æ‹…å½“è€…åˆ¥é›†è¨ˆ
    st.write("### å–¶æ¥­æ‹…å½“è€…åˆ¥é›†è¨ˆ")
    sales_summary = result_df.groupby('å–¶æ¥­æ‹…å½“è€…').agg({
        'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰': ['count', 'sum']
    }).round(0)
    sales_summary.columns = ['æ¡ˆä»¶æ•°', 'è¦‹è¾¼å£²ä¸Šé¡åˆè¨ˆï¼ˆä¸‡å††ï¼‰']
    sales_summary = sales_summary.sort_values('è¦‹è¾¼å£²ä¸Šé¡åˆè¨ˆï¼ˆä¸‡å††ï¼‰', ascending=False)
    st.dataframe(sales_summary)
    
    # Deal Typeåˆ¥é›†è¨ˆï¼ˆDeal Typeåˆ—ãŒã‚ã‚‹å ´åˆï¼‰
    if 'Deal Type' in result_df.columns:
        st.write("### Deal Typeåˆ¥é›†è¨ˆ")
        type_summary = result_df.groupby('Deal Type').agg({
            'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰': ['count', 'sum']
        }).round(0)
        type_summary.columns = ['æ¡ˆä»¶æ•°', 'è¦‹è¾¼å£²ä¸Šé¡åˆè¨ˆï¼ˆä¸‡å††ï¼‰']
        type_summary = type_summary.sort_values('è¦‹è¾¼å£²ä¸Šé¡åˆè¨ˆï¼ˆä¸‡å††ï¼‰', ascending=False)
        st.dataframe(type_summary)
    
    # ã‚µãƒãƒªãƒ¼
    total_amount = result_df['è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰'].sum()
    unique_sales = result_df['å–¶æ¥­æ‹…å½“è€…'].nunique()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç·æ¡ˆä»¶æ•°", f"{len(result_df)}ä»¶")
    with col2:
        st.metric("è¦‹è¾¼å£²ä¸Šé¡åˆè¨ˆ", f"{total_amount:,.0f}ä¸‡å††")
    with col3:
        st.metric("å–¶æ¥­æ‹…å½“è€…æ•°", f"{unique_sales}å")

# --- MAIN APPLICATION ---
# æ—¢å­˜ã®å—æ³¨æ¡ˆä»¶ãƒãƒ£ãƒ¼ãƒˆ
pipeline_chart_juchu(merged_df)

# åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ 
st.divider()

# æ–°ã—ã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ãƒ†ãƒ¼ãƒ–ãƒ«
table_of_pipeline_projects(merged_df)
