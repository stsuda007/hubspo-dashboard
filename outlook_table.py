import time
import json
import gspread
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from datetime import datetime
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import APIError

# --- Authentication ---
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
try:
    credentials_dict = json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT"])
    creds = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)
    gc = gspread.authorize(creds)
except KeyError:
    st.error("Googleã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`st.secrets`ã«`GOOGLE_SERVICE_ACCOUNT`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- Spreadsheet settings ---
SPREADSHEET_KEY = "1Ra_tPm2u5K4ikxacw1vdQqY_YQg-JekMsM-ZhaaVFKg"
DEALS_SHEET = "Deals"
STAGES_SHEET = "OtherParams"
USERS_SHEET = "Users"

# --- Data fetching function (cached & with retry) ---
@st.cache_data(ttl=300, show_spinner="Google Sheets ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
def load_data_with_retry(max_retries=3, delay=5):
    attempt = 0
    while attempt < max_retries:
        try:
            deals_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(DEALS_SHEET)
            stages_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(STAGES_SHEET)
            users_ws = gc.open_by_key(SPREADSHEET_KEY).worksheet(USERS_SHEET)

            deals_data = pd.DataFrame(deals_ws.get_all_records())
            stages_data = pd.DataFrame(stages_ws.get("A2:B12"), columns=["Stage ID", "Stage Name"])
            users_data = pd.DataFrame(users_ws.get_all_records())
            return deals_data, stages_data, users_data

        except APIError as e:
            if "429" in str(e):
                st.warning(f"APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{delay}ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...ï¼ˆ{attempt + 1}/{max_retries}ï¼‰")
                time.sleep(delay)
                attempt += 1
            else:
                st.error(f"Google Sheets API ã‚¨ãƒ©ãƒ¼: {e}")
                break

    st.error("Google Sheetsã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¾Œã»ã©å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
    return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# --- Load data ---
deals_df, stages_df, users_df = load_data_with_retry()

if deals_df.empty:
    st.stop()

# --- Convert IDs to names ---
users_df["Full Name"] = users_df["First Name"].fillna("") + " " + users_df["Last Name"].fillna("")
users_df = users_df.rename(columns={"ID": "User ID"})
deals_df = deals_df.rename(columns={"Deal owner": "User ID", "Deal Stage": "Stage ID"})

# Convert columns to numeric safely
deals_df["User ID"] = pd.to_numeric(deals_df["User ID"], errors="coerce")
deals_df["Stage ID"] = pd.to_numeric(deals_df["Stage ID"], errors="coerce")
stages_df["Stage ID"] = pd.to_numeric(stages_df["Stage ID"], errors="coerce")

# Clean up non-numeric characters in deal amount and convert to numeric
deals_df['å—æ³¨é‡‘é¡'] = deals_df['å—æ³¨é‡‘é¡'].astype(str).str.replace(r'[^\d]', '', regex=True)
deals_df["å—æ³¨é‡‘é¡"] = pd.to_numeric(deals_df["å—æ³¨é‡‘é¡"], errors="coerce")

# Adjust deal amount for better readability
deals_df["å—æ³¨é‡‘é¡"] = (deals_df["å—æ³¨é‡‘é¡"] / 10000).fillna(0).astype(int)

merged_df = deals_df.merge(users_df[["User ID", "Full Name"]], on="User ID", how="left")
merged_df = merged_df.merge(stages_df, on="Stage ID", how="left")

# --- Function to create the deals pipeline chart ---
def pipeline_chart_juchu(df):
    st.title("HubSpot Deals ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.subheader("å—æ³¨æ¡ˆä»¶ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ")
    st.write("å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°:", len(df))

    # Filter for 'å—æ³¨' (won) deals
    df_filtered = df[df['å—æ³¨/å¤±æ³¨'] == 'å—æ³¨'].copy()
    st.write("å—æ³¨ãƒ•ãƒ©ã‚°ã®ãƒ‡ãƒ¼ã‚¿æ•°:", len(df_filtered))

    # Convert date columns to datetime
    date_columns = ['åˆå›å•†è«‡å®Ÿæ–½æ—¥', 'å—æ³¨æ—¥', 'å—æ³¨ç›®æ¨™æ—¥', 'æœ‰å„Ÿãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç™ºè¡Œ', 'æ¦‚ç®—è¦‹ç©æå‡ºæ—¥', 'å ±å‘Š/ææ¡ˆæ—¥','æœ€çµ‚è¦‹ç©æå‡ºæ—¥', 'Create Date']
    for col in date_columns:
        if col in df_filtered.columns:
            df_filtered[col] = pd.to_datetime(df_filtered[col], errors='coerce')

    # Remove deals with no 'å—æ³¨æ—¥'
    df_filtered = df_filtered.dropna(subset=['å—æ³¨æ—¥'])
    st.write("å—æ³¨æ—¥ä¸è¨˜è¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿æ•°:", len(df_filtered))
    
    # Fill missing 'åˆå›å•†è«‡å®Ÿæ–½æ—¥' with 'Create Date'
    df_filtered['åˆå›å•†è«‡å®Ÿæ–½æ—¥'] = df_filtered['åˆå›å•†è«‡å®Ÿæ–½æ—¥'].fillna(df_filtered['Create Date'])
    
    if df_filtered.empty:
        st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å—æ³¨æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    df_plot = df_filtered.copy()
    df_plot['æ¡ˆä»¶å'] = df_plot['Deal Name'] + '<br>' + '(' + df_plot['ãƒªãƒ¼ãƒ‰çµŒè·¯'] + ')'
    df_plot['Start'] = df_plot['åˆå›å•†è«‡å®Ÿæ–½æ—¥']
    df_plot['Finish'] = df_plot['å—æ³¨æ—¥']

    df_plot = df_plot.dropna(subset=['Start', 'Finish'])
    st.write("æœ€çµ‚çš„ãªã‚°ãƒ©ãƒ•è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿æ•°:", len(df_plot))

    if df_plot.empty:
        st.info("ãƒ—ãƒ­ãƒƒãƒˆå¯èƒ½ãªå—æ³¨æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    df_plot = df_plot.sort_values('Start')

    # Ensure the x_start and x_end columns are datetime
    df_plot['Start'] = pd.to_datetime(df_plot['Start'], errors='coerce')
    df_plot['Finish'] = pd.to_datetime(df_plot['Finish'], errors='coerce')

    # Check for any NaT (Not a Time) values after conversion
    if df_plot['Start'].isna().any() or df_plot['Finish'].isna().any():
        st.error("Some dates in 'Start' or 'Finish' are invalid or missing.")
        st.stop()

    # Create the Plotly Gantt chart
    fig = px.timeline(
        df_plot,
        x_start="Start",
        x_end="Finish",
        y="æ¡ˆä»¶å",  # Adjust as per your column name for the task
        color="å–¶æ¥­æ‹…å½“è€…",  # Adjust as per your column name for the owner
        title="å—æ³¨æ¡ˆä»¶ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"
    )

    fig.update_layout(
        xaxis_title="æ—¥æ™‚",
        yaxis_title="æ¡ˆä»¶å",
        showlegend=True,
        height=400
    )

    st.plotly_chart(fig)

# --- NEW: Pipeline Projects Table Function ---
def table_of_pipeline_projects(df):
    st.subheader("ğŸ“Š ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¡ˆä»¶ä¸€è¦§")
    
    # Convert date columns
    for col in ['å—æ³¨ç›®æ¨™æ—¥', 'ç´å“äºˆå®šæ—¥']:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')

    # Filter for pipeline condition
    df_pipeline = df[df['å—æ³¨ç›®æ¨™æ—¥'].notna() | df['ç´å“äºˆå®šæ—¥'].notna()]

    if df_pipeline.empty:
        st.info("å—æ³¨ç›®æ¨™æ—¥ã¾ãŸã¯ç´å“äºˆå®šæ—¥ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹æ¡ˆä»¶ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # Display the filtered DataFrame
    display_df = df_pipeline.copy()
    display_df = display_df.rename(columns={'Full Name': 'å–¶æ¥­æ‹…å½“è€…', 'Deal Name': 'æ¡ˆä»¶å', 'å—æ³¨é‡‘é¡': 'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰'})
    
    # Format date columns
    display_df['äºˆå®šæ—¥'] = display_df.apply(lambda row: f"å—æ³¨ç›®æ¨™: {row['å—æ³¨ç›®æ¨™æ—¥'].strftime('%Y-%m-%d')}" if pd.notna(row['å—æ³¨ç›®æ¨™æ—¥']) else "", axis=1)

    # Sorting
    display_df = display_df.sort_values(by=['å–¶æ¥­æ‹…å½“è€…', 'è¦‹è¾¼å£²ä¸Šé¡ï¼ˆä¸‡å††ï¼‰'], ascending=[True, False])

    st.dataframe(display_df)

# --- MAIN APPLICATION ---
pipeline_chart_juchu(merged_df)
st.divider()
table_of_pipeline_projects(merged_df)
